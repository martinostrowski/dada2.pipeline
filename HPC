
#Rscript for running on the UTS HPC
#Example input" Rscript --verbose do-dada2ca.r 1 > output.ca.1.out"
#setup section 

args = commandArgs(trailingOnly=TRUE);
library(R.utils);
library(dada2);
library(ShortRead); packageVersion("ShortRead") # dada2 depends on this
library(tidyverse); packageVersion("dplyr") # for manipulating data
library(Biostrings);  # for creating the final graph at the end of the pipeline
library(Hmisc); packageVersion("Hmisc") # for creating the final graph at the end of the pipeline
#library(plotly); packageVersion("plotly") # enables creation of interactive graphs, especially helpful for quality plots

#inputs section (edit primers and paths as appropriate
setwd("/shared/c3/bio_db/BPA/a16s/");
plates<-read_csv('A16SNRSplates.csv');
#primers
FWD <- "TTCCGGTTGATCCYGCCGGA";  ## CHANGE ME to your forward primer sequence Archaea 16S: A2f/Arch21f Brown et al 
REV <- "GWATTACCGCGGCKGCTG"; ## CHANGE ME...Bacteria/Archaea 16S: 519r

p=args[1];
#rerun for all unzipped plates
#setwd("~/australian-microbiome-2/B862T")

#unzip all downloaded files using MAC terminal and the following code: gunzip *.fastq.gz

# Set path to shared data folder and contents
#data.fp <- "~/australian-microbiome-2/B862T"# CHANGE ME to the directory containing the fastq files after unzipping.

plates[p,1];
data.fp.gz <- (paste("/shared/c3/bio_db/BPA/a16s/", plates[p,1], "/",sep=""));


# List all files in shared folder to check path
files.fp.gz<-list.files(data.fp.gz,  pattern="fastq.gz");


for (i in seq_along (files.fp.gz)){
              gunzip(filename=paste(data.fp.gz,files.fp.gz[i],sep=""), overwrite=T)}
              
data.fp <- (paste("/shared/c3/bio_db/BPA/a16s/", plates[p,1], "/", sep=""));  

# Forward and reverse fastq filenames have format: SAMPLENAME_R1_001.fastq and SAMPLENAME_R2_001.fastq
fnFs <- sort(list.files(data.fp, pattern="_R1.fastq", full.names = TRUE));
fnRs <- sort(list.files(data.fp, pattern="_R2.fastq", full.names = TRUE));
# Extract sample names, assuming filenames have format: SAMPLENAME_XXX.fastq
sample.names <- sapply(strsplit(basename(fnFs), "_"), `[`, 1);

QplotsFs <- file.path(data.fp, "QplotsFs", paste0(sample.names, "_F_filt.fastq"));
QplotsRs <- file.path(data.fp, "QplotsRs", paste0(sample.names, "_R_filt.fastq"));
names(QplotsFs) <- sample.names;
names(QplotsRs) <- sample.names;

#change the 20 to be the number of samples that you have or that you want to plot
fwd.plot.quals <- plotQualityProfile(fnFs[1:10]);
ggsave(paste("fwd.qualplot.", plates[p,1],".pdf", sep=""),fwd.plot.quals, device="pdf");

rev.plot.quals <- plotQualityProfile(fnRs[1:10]);
ggsave(paste("rev.qualplot.", plates[p,1], ".pdf",sep=""), rev.plot.quals, device="pdf");

# Forward and reverse fastq filenames have format: SAMPLENAME_R1_001.fastq and SAMPLENAME_R2_001.fastq
fnFs <- sort(list.files(data.fp, pattern="L001_R1.fastq", full.names = TRUE));
fnRs <- sort(list.files(data.fp, pattern="L001_R2.fastq", full.names = TRUE));
# Extract sample names, assuming filenames have format: SAMPLENAME_XXX.fastq
sample.names <- sapply(strsplit(basename(fnFs), "_"), `[`, 1);

allOrients <- function(primer) {
    # Create all orientations of the input sequence
    require(Biostrings)
    dna <- DNAString(primer)  # The Biostrings works w/ DNAString objects rather than character vectors
    orients <- c(Forward = dna, Complement = complement(dna), Reverse = reverse(dna), 
        RevComp = reverseComplement(dna))
    return(sapply(orients, toString))  # Convert back to character vector
}
FWD.orients <- allOrients(FWD);
REV.orients <- allOrients(REV);
#FWD.orients

fnFs.filtN <- file.path(data.fp, "filtN", basename(fnFs)); # Put N-filterd files in filtN/ subdirectory
fnRs.filtN <- file.path(data.fp, "filtN", basename(fnRs));
filterAndTrim(fnFs, fnFs.filtN, fnRs, fnRs.filtN, maxN = 0, multithread = 16, compress=F);


cutadapt <- "/shared/c3/apps/anaconda3/bin/cutadapt" # CHANGE ME to the cutadapt path on your machine
system2(cutadapt, args = "--version") # Run shell commands from R

path.cut <- file.path(data.fp, "cutadapt")
if(!dir.exists(path.cut)) dir.create(path.cut)
fnFs.cut <- file.path(path.cut, basename(fnFs))
fnRs.cut <- file.path(path.cut, basename(fnRs))

FWD.RC <- dada2:::rc(FWD)
REV.RC <- dada2:::rc(REV)
# Trim FWD and the reverse-complement of REV off of R1 (forward reads)
R1.flags <- paste("-g", FWD, "-a", REV.RC) 
# Trim REV and the reverse-complement of FWD off of R2 (reverse reads)
R2.flags <- paste("-G", REV, "-A", FWD.RC) 
# Run Cutadapt
for(i in seq_along(fnFs)) {
  system2(cutadapt, args = c(R1.flags, R2.flags, "-n", 2, # -n 2 required to remove FWD and REV from reads
                             "-o", fnFs.cut[i], "-p", fnRs.cut[i], # output files
                             fnFs.filtN[i], fnRs.filtN[i])) # input files
}



data.fp <- (paste("/shared/c3/bio_db/BPA/a16s/", plates[p,1], "/cutadapt/", sep="")) #plates$plates[args[1]] 
# List all files in shared folder to check path
list.files(data.fp);

# Forward and reverse fastq filenames have format: SAMPLENAME_R1_001.fastq and SAMPLENAME_R2_001.fastq
cutFs <- sort(list.files(data.fp, pattern="_R1.fastq", full.names = TRUE));
cutRs <- sort(list.files(data.fp, pattern="_R2.fastq", full.names = TRUE));
# Extract sample names, assuming filenames have format: SAMPLENAME_XXX.fastq
sample.names <- sapply(strsplit(basename(cutFs), "_"), `[`, 1);


primerHits <- function(primer, fn) {
    # Counts number of reads in which the primer is found
    nhits <- vcountPattern(primer, sread(readFastq(fn)), fixed = FALSE)
    return(sum(nhits > 0));
}
rbind(FWD.ForwardReads = sapply(FWD.orients, primerHits, fn = fnFs.cut[[1]]), 
    FWD.ReverseReads = sapply(FWD.orients, primerHits, fn = fnRs.cut[[1]]), 
    REV.ForwardReads = sapply(REV.orients, primerHits, fn = fnFs.cut[[1]]), 
    REV.ReverseReads = sapply(REV.orients, primerHits, fn = fnRs.cut[[1]]));

#Trim left and right sides based on primer size, as follows trimLeft = c(FWD_PRIMER_LEN, REV_PRIMER_LEN)
 #Forward (20bp)             Reverse  (20bp)        
#"TTCCGGTTGATCCYGCCGGA"  "AGGCCGYCCTAGTTGGCCTT"  
#trimLeft = c(20, 20);


trimFs <- file.path(data.fp, "trimmed", paste0(sample.names, "_F_dada2.fastq"));
trimRs <- file.path(data.fp, "trimmed", paste0(sample.names, "_R_dada2.fastq"));
names(filtFs) <- sample.names;
names(filtRs) <- sample.names;


out <- filterAndTrim(cutFs, trimFs, cutRs, trimRs, truncLen=c(250,228),
              maxN=0, maxEE=c(6,10), truncQ=2, rm.phix=TRUE,
              compress=FALSE, multithread=16, minLen = 50, matchIDs=TRUE); # On Windows set multithread=FALSE
head(out);

errF <- learnErrors(filtFs, multithread=16);

errR <- learnErrors(filtRs, multithread=16);





plot.errors <- plotErrors(errF, nominalQ=TRUE);
ggsave(paste("plot.errors.",plates[p,1], ".pdf", sep=""), plot.errors, device="pdf");

derepFs<-derepFastq(trimFs);
derepRs<-derepFastq(trimRs);


dadaFs <- dada(derepFs, err=errF, multithread=16);

dadaRs <- dada(derepRs, err=errR, multithread=16);

mergers <- mergePairs(dadaFs, derepFs, dadaRs, derepRs, verbose=TRUE);
# Inspect the merger data.frame from the first sample
head(mergers[[1]]);

seqtab <- makeSequenceTable(mergers);
dim(seqtab);


# Inspect distribution of sequence lengths
table(nchar(getSequences(seqtab)));

seqtab.nochim <- removeBimeraDenovo(seqtab, method="consensus", multithread=16, verbose=TRUE);

dim(seqtab.nochim);

sum(seqtab.nochim)/sum(seqtab);

getN <- function(x) sum(getUniques(x));
track <- cbind(out, sapply(dadaFs, getN), sapply(dadaRs, getN), sapply(mergers, getN), rowSums(seqtab.nochim));
# If processing a single sample, remove the sapply calls: e.g. replace sapply(dadaFs, getN) with getN(dadaFs)
colnames(track) <- c("input", "filtered", "denoisedF", "denoisedR", "merged", "nonchim");
rownames(track) <- sample.names;
head(track);


plotLengthDistro <- function(st) {
  require(ggplot2)
  tot.svs <- table(nchar(colnames(st)))
  tot.reads <- tapply(colSums(st), nchar(colnames(st)), sum)
  df <- data.frame(Length=as.integer(c(names(tot.svs), names(tot.reads))),
                   Count=c(tot.svs, tot.reads),
                   Type=rep(c("SVs", "Reads"), times=c(length(tot.svs), length(tot.reads))))
  pp <- ggplot(data=df, aes(x=Length, y=Count, color=Type)) + geom_point() + facet_wrap(~Type, scales="free_y") + theme_bw() + xlab("Amplicon Length")
  pp
  }

plotLengthDistro(seqtab.nochim);
plotLengthDist.log10 <-plotLengthDistro(seqtab.nochim) + scale_y_log10();
ggsave(paste("plotLengthDist.log10.", plates[p,1], "T.pdf", sep=""), plotLengthDist.log10, device="pdf")


#library(phyloseq); packageVersion("phyloseq")
#library(Biostrings); packageVersion("Biostrings")
#install.packages("tidyr")
#library(tidyr)
#library(dplyr)

sample <- rownames(seqtab.nochim);
sequence <- colnames(seqtab.nochim);

#check the col names and check how many ASVs that you are losing in the pipeline
colnames(seqtab.nochim);
#what % had chimera's vs non-chimeras?
sum(seqtab.nochim)/sum(seqtab);
#this is the %
sum(rev(sort(colSums(seqtab.nochim)))[1:1000])/sum(colSums(seqtab.nochim));

# Flip table
seqtab.t <- as.data.frame(t(seqtab.nochim));
write.csv(seqtab.t, paste("ASV.table.", plates[p,1] ,".csv", sep=""), col.names=NA);


# tracking reads by percentage
track_pct <- track %>% 
  data.frame() %>%
  mutate(Sample = rownames(.),
         filtered_pct = ifelse(filtered == 0, 0, 100 * (filtered/input)),
         denoisedF_pct = ifelse(denoisedF == 0, 0, 100 * (denoisedF/filtered)),
         denoisedR_pct = ifelse(denoisedR == 0, 0, 100 * (denoisedR/filtered)),
         merged_pct = ifelse(merged == 0, 0, 100 * merged/((denoisedF + denoisedR)/2)),
         nonchim_pct = ifelse(nonchim == 0, 0, 100 * (nonchim/merged)),
         total_pct = ifelse(nonchim == 0, 0, 100 * nonchim/input)) %>%
  select(Sample, ends_with("_pct"));

track_pct_avg <- track_pct %>% summarize_at(vars(ends_with("_pct")), 
                                            list(avg = mean));
head(track_pct_avg);

track_pct_med <- track_pct %>% summarize_at(vars(ends_with("_pct")), 
                                            list(avg = stats::median));
head(track_pct_avg);

head(track_pct_med);


track_plot <- track %>% 
  data.frame() %>%
  mutate(Sample = rownames(.)) %>%
  gather(key = "Step", value = "Reads", -Sample) %>%
  mutate(Step = factor(Step, 
                       levels = c("input", "filtered", "denoisedF", "denoisedR", "merged", "nonchim"))) %>%
  ggplot(aes(x = Step, y = Reads)) +
  geom_line(aes(group = Sample), alpha = 0.2) +
  geom_point(alpha = 0.5, position = position_jitter(width = 0)) + 
  stat_summary(fun.y = median, geom = "line", group = 1, color = "steelblue", size = 1, alpha = 0.5) +
  stat_summary(fun.y = median, geom = "point", group = 1, color = "steelblue", size = 2, alpha = 0.5) +
  stat_summary(fun.data = median_hilow, fun.args = list(conf.int = 0.5), 
               geom = "ribbon", group = 1, fill = "steelblue", alpha = 0.2) +
  geom_label(data = t(track_pct_avg[1:5]) %>% data.frame() %>% 
               rename(Percent = 1) %>%
               mutate(Step = c("filtered", "denoisedF", "denoisedR", "merged", "nonchim"),
                      Percent = paste(round(Percent, 2), "%")),
             aes(label = Percent), y = 1.1 * max(track[,2])) +
  geom_label(data = track_pct_avg[6] %>% data.frame() %>%
               rename(total = 1),
             aes(label = paste("Total\nRemaining:\n", round(track_pct_avg[1,6], 2), "%")), 
             y = mean(track[,6]), x = 6.5) +
  expand_limits(y = 1.1 * max(track[,2]), x = 7) +
  theme_classic();

ggsave(paste("track_plot.", plates[p,1],".pdf", sep=""), track_plot, device="pdf");

q();
